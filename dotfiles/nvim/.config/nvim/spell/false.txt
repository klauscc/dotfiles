{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QAlso, another thing that we'll do this week is to get feedback on the submitted ECCV drafts.\\E$"}
{"rule":"EN_QUOTES","sentence":"^\\QThus, â€œapproximating\" short-term features with the features from LMM provides large efficiency gains (both in terms of training time and GPU memory), while still achieving excellent TAL accuracy, which we demonstrate in our experimental section.\\E$"}
{"rule":"PASSIVE_VOICE","sentence":"^\\QThis works well in the TAL setting because the short-term feature extractor is already pretrained (e.g., on an action recognition task) and thus, it evolves more slowly than the other modules in the network (i.e., it uses a smaller learning rate than the other parts of the network).\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qbackgroundcolor=, basicstyle=, columns=fullflexible, breaklines=true, captionpos=b, commentstyle=, keywordstyle=,\\E$"}
{"rule":"THREE_NN","sentence":"^\\QOur method consists of four high-level components: (i) a short-term feature extractor, (ii) a long memory module, (iii) a temporal consistency module and (iv) a temporal boundary localization module.\\E$"}
{"rule":"THREE_NN","sentence":"^\\QAfterward, the temporal boundary localization module outputs temporal boundaries and action categories associated with each action instance.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\QTransformerLayer \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q , in which \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the layer index, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the refined features of TCM.\\E$"}
{"rule":"TOO_LONG_SENTENCE","sentence":"^\\QHowever, due to the high GPU memory cost needed to process long untrimmed videos, the majority of existing methods sacrifice the representational power of the short-term feature extractor, by either freezing the backbone \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q or using a very small spatial video resolution (e.g., \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q) \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QFormally, given the video features \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q from the long memory module, the TCM refines the feature using three Transformer layers: \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\QTransformerLayer \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q , in which \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the layer index, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q and \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q is the refined features of TCM.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qcan incorporate with any existing TBLM.\\E$"}
{"rule":"COMMA_PARENTHESIS_WHITESPACE","sentence":"^\\QDue to the strong representational power of , this simple modification can achieve a high action classification accuracy and thus, eliminate the necessity for an external action recognition classifier.\\E$"}
{"rule":"EN_UPPER_CASE_NGRAM","sentence":"^\\QAblation Study.\\E$"}
